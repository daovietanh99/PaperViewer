<!DOCTYPE html>

<title>PaperViewer</title>

<meta charset="utf-8">

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.4.0/css/bootstrap.min.css" crossorigin="anonymous">
<link rel="stylesheet" href="css/style.css">
<link rel="preconnect" href="https://fonts.gstatic.com">

<style>
    html, body {
        overflow-x:hidden
    }
    /* greek-ext */
    @font-face {
        font-family: 'Roboto';
        font-style: normal;
        font-weight: 300;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/roboto/v20/KFOlCnqEu92Fr1MmSU5fCBc4EsA.woff2) format('woff2');
        unicode-range: U+1F00-1FFF;
    }

    /* greek */
    @font-face {
        font-family: 'Roboto';
        font-style: normal;
        font-weight: 300;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/roboto/v20/KFOlCnqEu92Fr1MmSU5fBxc4EsA.woff2) format('woff2');
        unicode-range: U+0370-03FF;
    }

    /* latin-ext */
    @font-face {
        font-family: 'Roboto';
        font-style: normal;
        font-weight: 300;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/roboto/v20/KFOlCnqEu92Fr1MmSU5fChc4EsA.woff2) format('woff2');
        unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* latin */
    @font-face {
        font-family: 'Roboto';
        font-style: normal;
        font-weight: 300;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/roboto/v20/KFOlCnqEu92Fr1MmSU5fBBc4.woff2) format('woff2');
        unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
    }

    /* greek-ext */
    @font-face {
        font-family: 'Roboto';
        font-style: normal;
        font-weight: 400;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/roboto/v20/KFOmCnqEu92Fr1Mu7mxKOzY.woff2) format('woff2');
        unicode-range: U+1F00-1FFF;
    }

    /* greek */
    @font-face {
        font-family: 'Roboto';
        font-style: normal;
        font-weight: 400;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/roboto/v20/KFOmCnqEu92Fr1Mu4WxKOzY.woff2) format('woff2');
        unicode-range: U+0370-03FF;
    }

    /* latin-ext */
    @font-face {
        font-family: 'Roboto';
        font-style: normal;
        font-weight: 400;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/roboto/v20/KFOmCnqEu92Fr1Mu7GxKOzY.woff2) format('woff2');
        unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
    }

    /* latin */
    @font-face {
        font-family: 'Roboto';
        font-style: normal;
        font-weight: 400;
        font-display: swap;
        src: url(https://fonts.gstatic.com/s/roboto/v20/KFOmCnqEu92Fr1Mu4mxK.woff2) format('woff2');
        unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
    }

    #face_rec::before {
        padding-top: 30%;
    }

    #3d_face::before {
        padding-top: 50%;
    }

    #v_face::before {
        padding-top: 30%;
    }
</style>

<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/swiper@10/swiper-bundle.min.css"
/>

<script src="https://cdn.jsdelivr.net/npm/swiper@10/swiper-bundle.min.js"></script>

<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<body>
    <div class="swiper-container">
    
    <!-- swiper slides -->
    <div class="swiper-wrapper">
        <div class="container swiper-slide">
        <div class="row mb-2 mt-4" id="paper-title">
            <h1 class="col-md-12 text-center">
                Face Recognition System 
            </h1>
            <h3 class="col-md-12 text-center">
                Face Recognition System for Unconstrained Condition
            </h3>
            <h3 class="col-md-12 text-center">
                <small>ATC' 2023 (Oral)</small>
            </h3>
        </div>

        <div class="row" id="authors">
            <div class="mx-auto text-center">
                <ul class="list-inline mb-0">
                    <li class="list-inline-item">
                        <a href="https://people.eecs.berkeley.edu/~sfk/">Viet-Anh Dao</a>
                        <sup>*</sup>
                    </li>

                    <li class="list-inline-item">
                        <a href="https://alexyu.net">Hoang-Anh Nguyen The</a>
                        <sup>*</sup>
                    </li>

                    <li class="list-inline-item">
                        <a href="https://www.matthewtancik.com">Dang-Ha Nguyen</a>
                    </li>

                    <li class="list-inline-item">
                        <a href="https://www.linkedin.com/in/qinhong-chen/">Viet-Bac Nguyen</a>
                    </li>

                    <li class="list-inline-item">
                        <a href="http://people.eecs.berkeley.edu/~brecht/">Thom Tran</a>
                    </li>

                </ul>
                <ul class="list-inline mb-0" id="institution">
                    <li class="list-inline-item">
                        Vietnam Korea Institute of Science and Technology
                    </li>
                    <li class="list-inline-item">
                        <sup>*</sup>
                        Equal contribution
                    </li>
                </ul>
            </div>
        </div>
        <div class="row mb-2" id="links">
            <div class="mx-auto">
                <ul class="nav">
                    <li class="nav-item text-center">
                        <a href="https://edas.info/showPaper.php?m=1570924319" class="nav-link" title="Temp link">
                            <svg style="width:48px;height:48px" viewBox="0 0 24 24">
                                <path fill="currentColor" d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z" />
                            </svg><br>
                            Paper
                        </a>
                    <li class="nav-item text-center">
                        <a href="https://github.com/daovietanh190499/face_rec" class="nav-link">
                            <svg style="width:48px;height:48px" viewBox="0 0 65 65">
                                <path fill="currentColor" d="M32 0a32.021 32.021 0 0 0-10.1 62.4c1.6.3 2.2-.7 2.2-1.5v-6c-8.9 1.9-10.8-3.8-10.8-3.8-1.5-3.7-3.6-4.7-3.6-4.7-2.9-2 .2-1.9.2-1.9 3.2.2 4.9 3.3 4.9 3.3 2.9 4.9 7.5 3.5 9.3 2.7a6.93 6.93 0 0 1 2-4.3c-7.1-.8-14.6-3.6-14.6-15.8a12.27 12.27 0 0 1 3.3-8.6 11.965 11.965 0 0 1 .3-8.5s2.7-.9 8.8 3.3a30.873 30.873 0 0 1 8-1.1 30.292 30.292 0 0 1 8 1.1c6.1-4.1 8.8-3.3 8.8-3.3a11.965 11.965 0 0 1 .3 8.5 12.1 12.1 0 0 1 3.3 8.6c0 12.3-7.5 15-14.6 15.8a7.746 7.746 0 0 1 2.2 5.9v8.8c0 .9.6 1.8 2.2 1.5A32.021 32.021 0 0 0 32 0z" />
                            </svg>
                            <br>
                            Code
                        </a>
                </ul>
            </div>
        </div>
        <div class="row mb-3 pt-2">
            <div class="col-md-8 mx-auto">
               <!-- <div class="embed-responsive embed-responsive-16by9 pb-3" id="face_rec">
                    <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/KCDd7UFO1d0" frameborder="0" allow="accelerometer; autoplay muted; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    <img class="embed-responsive-item" src="imgs/diagram.png" style="height: auto;">
                </div> -->
                <img class="img-responsive" src="imgs/diagram.png">
                <p class="text-justify mt-2 pt-3">
                    Our approach focuses on integrating
                    state-of-the-art techniques proposed by various authors. These
                    techniques have gained recognition as being at the forefront
                    of face recognition research, exhibiting top efficiency and
                    performance in their respective tasks. By combining these
                    established techniques, our system aims to achieve optimal
                    accuracy and efficiency in the challenging domain of unconstrained face recognition
                </p>
            </div>
        </div>
        <div class="row mb-3">
            <div class="col-md-8 mx-auto">
                <h4>Results on VKIST</h4>
                <p>
                    We have effectively deployed our face recognition system in
                    two different locations: Vietnam - Korea Institute of Science
                    and Technology (VKIST), Fig. 2, and Tuoi Tho Kindergarten,
                    Hanoi. Each location required the system to handle a substantial number of individuals, ranging from 75 to 80 people
                    and aging from 3 to 70 years old. This setup allowed us to
                    assess the system’s performance under real-world conditions,
                    accommodating a diverse range of individuals
                </p>
                <img class="fullwid-vid" src="imgs/VKIST_face_rec.jpg">
            </div>
        </div>
        <div class="row mb-3">
            <div class="col-md-8 mx-auto">
                <h4>Acknowledgements</h4>
                <p class="text-justify">
                    This work was supported by the Ministry Project “The
                    extended research focuses on developing a synchronized image collection system from multiple cameras to enhance
                    the effectiveness of face recognition by incorporating facial
                    expression synthesis technology. The objective is to improve
                    the accuracy of facial recognition by capturing facial images
                    from different perspectives and synthesizing facial expressions.” of the Ministry of Science and Technology of Vietnam
                    (No.02.M02.2022).
                </p>
                <p class="text-justify">
                    This website is in part based on a template of <a href="http://mgharbi.com/">Micha&euml;l Gharbi</a>, also used in <a href="https://alexyu.net/pixelnerf">PixelNeRF</a> and <a href="https://alexyu.net/plenoctrees">PlenOctrees</a>.
                </p>
            </div>
        </div>
    </div> <!-- container -->

        <div class="container swiper-slide">
        <div class="row mb-2 mt-4" id="paper-title">
            <h1 class="col-md-12 text-center">
                3D Reconstruction
            </h1>
            <h3 class="col-md-12 text-center">
                A new 3D Face Model for Vietnamese based on Basel Face Model
            </h3>
            <h3 class="col-md-12 text-center">
                <small>ACIIDS 2022 (Oral)</small>
            </h3>
        </div>

        <div class="row" id="authors">
            <div class="mx-auto text-center">
                <ul class="list-inline mb-0">
                    <li class="list-inline-item">
                        <a href="https://people.eecs.berkeley.edu/~sfk/">Dang-Ha Nguyen</a>
                        <sup>*</sup>
                    </li>

                    <li class="list-inline-item">
                        <a href="https://alexyu.net">Hoang-Anh Nguyen The</a>
                        <sup>*</sup>
                    </li>

                    <li class="list-inline-item">
                        <a href="https://www.matthewtancik.com">Chau Ma Thi</a>
                    </li>
                </ul>
                <ul class="list-inline mb-0" id="institution">
                    <li class="list-inline-item">
                        Vietnam Korea Institute of Science and Technology
                    </li>
                    <li class="list-inline-item">
                        <sup>*</sup>
                        Equal contribution
                    </li>
                </ul>
            </div>
        </div>
        <div class="row mb-2" id="links">
            <div class="mx-auto">
                <ul class="nav">
                    <li class="nav-item text-center">
                        <a href="https://arxiv.org/abs/2112.05131" class="nav-link" title="Temp link">
                            <svg style="width:48px;height:48px" viewBox="0 0 24 24">
                                <path fill="currentColor" d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z" />
                            </svg><br>
                            Paper
                        </a>
                    <li class="nav-item text-center">
                        <a href="https://github.com/sxyu/svox2" class="nav-link">
                            <svg style="width:48px;height:48px" viewBox="0 0 65 65">
                                <path fill="currentColor" d="M32 0a32.021 32.021 0 0 0-10.1 62.4c1.6.3 2.2-.7 2.2-1.5v-6c-8.9 1.9-10.8-3.8-10.8-3.8-1.5-3.7-3.6-4.7-3.6-4.7-2.9-2 .2-1.9.2-1.9 3.2.2 4.9 3.3 4.9 3.3 2.9 4.9 7.5 3.5 9.3 2.7a6.93 6.93 0 0 1 2-4.3c-7.1-.8-14.6-3.6-14.6-15.8a12.27 12.27 0 0 1 3.3-8.6 11.965 11.965 0 0 1 .3-8.5s2.7-.9 8.8 3.3a30.873 30.873 0 0 1 8-1.1 30.292 30.292 0 0 1 8 1.1c6.1-4.1 8.8-3.3 8.8-3.3a11.965 11.965 0 0 1 .3 8.5 12.1 12.1 0 0 1 3.3 8.6c0 12.3-7.5 15-14.6 15.8a7.746 7.746 0 0 1 2.2 5.9v8.8c0 .9.6 1.8 2.2 1.5A32.021 32.021 0 0 0 32 0z" />
                            </svg>
                            <br>
                            Code
                        </a>
                </ul>
            </div>
        </div>
        <div class="row mb-3 pt-2">
            <div class="col-md-8 mx-auto">
                <div class="embed-responsive embed-responsive-16by9 pb-3" id="3d_face">
                    <img class="embed-responsive-item" src="imgs/face3d_diagram.png" style="height: auto;">
                </div>
                <p class="text-justify mt-2 pt-3">
                    We propose an approach that increases the accuracy of Vietnamese 3D faces generated from a single image by creating a new mean face shape
                    and training a convolution neural network with our dataset. This method is compact and can improve the quality of 3D face reconstruction
                    using facial image data with specific geographical and race characteristics.
                </p>
            </div>
        </div>
        <div class="row mb-3 pt-2">
            <div class="col-md-8 mx-auto">
                <p class="text-justify">
                    To generate a 3D face model from a single image,
                    we use 2 key components: <br>
                    • Generative face model: A base 3D face model
                    with a set of modifiable parameters for shape
                    and texture. <br>
                    • Deep-learning network: A convolutional neural
                    network (CNN) is required to extract the
                    features from the input image. The output
                    coefficients from the network will then be
                    combined with the parameters from the base
                    3D model to generate the desired face.
                </p>

            </div>
        </div>
        <div class="row mb-3">
            <div class="col-md-8 mx-auto">
                <h4>Result</h4>
                <img class="img-responsive" src="imgs/face3d_result.png" alt="Pipeline (figure 2)">
                <p class="text-justify">
                    This website is in part based on a template of <a href="http://mgharbi.com/">Micha&euml;l Gharbi</a>, also used in <a href="https://alexyu.net/pixelnerf">PixelNeRF</a> and <a href="https://alexyu.net/plenoctrees">PlenOctrees</a>.
                </p>
            </div>
        </div>
    </div> <!-- container -->

        <div class="container swiper-slide">
        <div class="row mb-2 mt-4" id="paper-title">
            <h1 class="col-md-12 text-center">
                V-FACE
            </h1>
            <h3 class="col-md-12 text-center">
                A Large-Scale Vietnamese Face Image Database in Unconstrained Environments
            </h3>
            <h3 class="col-md-12 text-center">
                <small> iRobotics 2022, ISSN: 2616-8170</small>
            </h3>
        </div>

        <div class="row" id="authors">
            <div class="mx-auto text-center">
                <ul class="list-inline mb-0">
                    <li class="list-inline-item">
                        <a href="https://people.eecs.berkeley.edu/~sfk/">Hieu Duong</a>
                        <sup>*</sup>
                    </li>

                    <li class="list-inline-item">
                        <a href="https://alexyu.net">Hoang-Anh Nguyen The</a>
                        <sup>*</sup>
                    </li>

                    <li class="list-inline-item">
                        <a href="https://www.matthewtancik.com">Thom Tran</a>
                    </li>

                    <li class="list-inline-item">
                        <a href="https://www.matthewtancik.com">Viet-Bac Nguyen</a>
                    </li>

                    <li class="list-inline-item">
                        <a href="https://www.matthewtancik.com">Viet-Anh Dao</a>
                    </li>
                </ul>
                <ul class="list-inline mb-0" id="institution">
                    <li class="list-inline-item">
                        Vietnam Korea Institute of Science and Technology
                    </li>
                    <li class="list-inline-item">
                        <sup>*</sup>
                        Equal contribution
                    </li>
                </ul>
            </div>
        </div>
        <div class="row mb-2" id="links">
            <div class="mx-auto">
                <ul class="nav">
                    <li class="nav-item text-center">
                        <a href="https://arxiv.org/abs/2112.05131" class="nav-link" title="Temp link">
                            <svg style="width:48px;height:48px" viewBox="0 0 24 24">
                                <path fill="currentColor" d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z" />
                            </svg><br>
                            Paper
                        </a>
                    <li class="nav-item text-center">
                        <a href="https://github.com/sxyu/svox2" class="nav-link">
                            <svg style="width:48px;height:48px" viewBox="0 0 65 65">
                                <path fill="currentColor" d="M32 0a32.021 32.021 0 0 0-10.1 62.4c1.6.3 2.2-.7 2.2-1.5v-6c-8.9 1.9-10.8-3.8-10.8-3.8-1.5-3.7-3.6-4.7-3.6-4.7-2.9-2 .2-1.9.2-1.9 3.2.2 4.9 3.3 4.9 3.3 2.9 4.9 7.5 3.5 9.3 2.7a6.93 6.93 0 0 1 2-4.3c-7.1-.8-14.6-3.6-14.6-15.8a12.27 12.27 0 0 1 3.3-8.6 11.965 11.965 0 0 1 .3-8.5s2.7-.9 8.8 3.3a30.873 30.873 0 0 1 8-1.1 30.292 30.292 0 0 1 8 1.1c6.1-4.1 8.8-3.3 8.8-3.3a11.965 11.965 0 0 1 .3 8.5 12.1 12.1 0 0 1 3.3 8.6c0 12.3-7.5 15-14.6 15.8a7.746 7.746 0 0 1 2.2 5.9v8.8c0 .9.6 1.8 2.2 1.5A32.021 32.021 0 0 0 32 0z" />
                            </svg>
                            <br>
                            Code
                        </a>
                </ul>
            </div>
        </div>
        <div class="row mb-3 pt-2">
            <div class="col-md-8 mx-auto">
                <div class="embed-responsive embed-responsive-16by9 pb-3" id="v_face">
                    <img class="embed-responsive-item" src="imgs/vface_diagram.png" style="height: auto;">
                </div>
                <p class="text-justify mt-2 pt-3">
                    In this paper, we introduce a new large-scale face image database for Vietnamese and describe a capturing system specifically designed to obtain the data. The V-FACE database contains more than 3 million high-quality images of more than 300 subjects and has a balanced ratio of genders. The database includes a variety of attributes, including different angles, lighting conditions, facial expressions, and occlusions with the combination of four types of accessories. 
                </p>
            </div>
        </div>
        <div class="row mb-3">
            <div class="col-md-8 mx-auto">
                <h4>Result</h4>
                <img class="img-responsive" src="imgs/vface_result.png" alt="Pipeline (figure 2)">
                <p class="text-justify">
                    This website is in part based on a template of <a href="http://mgharbi.com/">Micha&euml;l Gharbi</a>, also used in <a href="https://alexyu.net/pixelnerf">PixelNeRF</a> and <a href="https://alexyu.net/plenoctrees">PlenOctrees</a>.
                </p>
            </div>
        </div>
    </div> <!-- container -->

    </div>
    <div class="swiper-button-next"></div>
    <div class="swiper-button-prev"></div>
    </div>
    <script>
        var Swipes = new Swiper('.swiper-container', {
            loop: true,
            navigation: {
                nextEl: '.swiper-button-next',
                prevEl: '.swiper-button-prev',
            },
            autoplay: {
                delay: 30000,
                disableOnInteraction: false,
            },
        });

        window.mobileAndTabletCheck = function() {
            let check = false;
            (function(a) {
                if (/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino|android|ipad|playbook|silk/i.test(a) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0, 4))) check = true;
            })(navigator.userAgent || navigator.vendor || window.opera);
            return check;
        };


        if (mobileAndTabletCheck()) {
            document.getElementById('demo-warning').style.display = 'block';
            document.getElementById('demo-container').style.display = 'none';
            document.getElementById('demo-warning').innerHTML = "Unfortunately, mobile and tablet devices are not currently supported due to WebGL compatibility issues. We hope to support this in the future.";
        } else {
            var canvas = document.createElement('canvas');
            var gl = canvas.getContext('webgl');
            var tex_limit = gl.getParameter(gl.MAX_TEXTURE_SIZE);
            if (gl && gl instanceof WebGLRenderingContext) {
                const REQUIRED_TEX_LIMIT = 8192;
                if (tex_limit < REQUIRED_TEX_LIMIT) {
                    document.getElementById('demo-warning').style.display = 'block';
                    document.getElementById('demo-container').style.display = 'none';
                    document.getElementById('demo-warning').innerHTML = "Your GPU's maximum texture size is: " + tex_limit + " which is less than the minimum required (" + REQUIRED_TEX_LIMIT + ").  Please try another device, if possible.";
                }
            } else {
                document.getElementById('demo-warning').style.display = 'block';
                document.getElementById('demo-container').style.display = 'none';
                document.getElementById('demo-warning').innerHTML = "Your browser does not support WebGL, or WebGL was disabled. Please use a modern browser like Chrome or Firefox.";
            }
        }
    </script>
</body>
